{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "6ee7a6a3",
   "metadata": {},
   "source": [
    "## Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "id": "9842d8b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from enum import Enum\n",
    "import re\n",
    "import pandas\n",
    "import tkinter as tk\n",
    "import pandastable as pt\n",
    "from nltk.tree import *"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "ebdcec0f",
   "metadata": {},
   "source": [
    "## define an enumeration that lists token types"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "id": "7a83c4bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Token_type(Enum):  # listing all tokens type\n",
    "    setq = 1\n",
    "    setf = 2\n",
    "    dotimes = 3\n",
    "    when = 4\n",
    "    write = 5\n",
    "    left_brace = 6\n",
    "    dot=8\n",
    "    comment = 9\n",
    "    EqualOp = 10\n",
    "    LessThanOp = 11\n",
    "    GreaterThanOp = 12\n",
    "    NotEqualOp = 13\n",
    "    PlusOp = 14\n",
    "    MinusOp = 15\n",
    "    MultiplyOp = 16\n",
    "    DivideOp = 17\n",
    "    Identifier = 18\n",
    "    Constant = 19\n",
    "    Error = 20\n",
    "    right_brace = 21\n",
    "    NewLine=23\n",
    "    Atom=24\n",
    "    read=25\n",
    "    greaterThanOrEqual=26\n",
    "    lessThanOrEqual=27\n",
    "    print= 28\n",
    "    min=29\n",
    "    max = 30\n",
    "    defun=31\n",
    "    if_statement=32\n",
    "    and_op=33\n",
    "    or_op=34\n",
    "    not_op=35\n",
    "    incf=36\n",
    "    decf=37\n",
    "    mod=38\n",
    "    string=39\n",
    "    true=40\n",
    "    false=41\n",
    "    defconstant=42\n",
    "    rem=43"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "77639f13",
   "metadata": {},
   "source": [
    "## class token to hold string and token type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "id": "83a595a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "class token:\n",
    "    def __init__(self, lex, token_type):\n",
    "        self.lex = lex\n",
    "        self.token_type = token_type\n",
    "\n",
    "    def to_dict(self):\n",
    "        return {\n",
    "            'Lex': self.lex,\n",
    "            'token_type': self.token_type\n",
    "        }"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "528d931d",
   "metadata": {},
   "source": [
    "## Reserved word Dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "id": "85507875",
   "metadata": {},
   "outputs": [],
   "source": [
    "ReservedWords = {\n",
    "    \"setq\": Token_type.setq,\n",
    "    \"dotimes\":Token_type.dotimes,\n",
    "    \"when\":Token_type.when,\n",
    "    \"write\":Token_type.write,\n",
    "    \"read\":Token_type.read,\n",
    "    \"print\":Token_type.print,\n",
    "    \"if\":Token_type.if_statement,\n",
    "    \"incf\":Token_type.incf,\n",
    "    \"decf\":Token_type.decf,\n",
    "    \"t\":Token_type.true,\n",
    "    \"nil\":Token_type.false,\n",
    "    \"defconstant\":Token_type.defconstant,\n",
    "    \"mod\":Token_type.mod,\n",
    "    \"rem\":Token_type.rem\n",
    "}"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "3147e505",
   "metadata": {},
   "source": [
    "## Operators Dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "id": "7d7f5cd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "Operators = {\".\": Token_type.dot,\n",
    "             \";\": Token_type.comment,\n",
    "             \"=\": Token_type.EqualOp,\n",
    "             \"+\": Token_type.PlusOp,\n",
    "             \"-\": Token_type.MinusOp,\n",
    "             \"*\": Token_type.MultiplyOp,\n",
    "             \"/\": Token_type.DivideOp,\n",
    "             \"<\": Token_type.LessThanOp,\n",
    "             \">\": Token_type.GreaterThanOp,\n",
    "             \"(\": Token_type.left_brace,\n",
    "             \")\": Token_type.right_brace,\n",
    "             \"\\n\":Token_type.NewLine,\n",
    "             \"<=\":Token_type.lessThanOrEqual,\n",
    "             \">=\":Token_type.greaterThanOrEqual,\n",
    "             \"and\":Token_type.and_op,\n",
    "             \"or\":Token_type.or_op,\n",
    "             \"not\":Token_type.not_op,\n",
    "             \"mod\":Token_type.mod\n",
    "             } "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "124fb866",
   "metadata": {},
   "source": [
    "## Create Lists for Tokens and Errors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "id": "1007871f",
   "metadata": {},
   "outputs": [],
   "source": [
    "Tokens = [] \n",
    "Tokens_comment=[]\n",
    "errors = []"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "80919ab8",
   "metadata": {},
   "source": [
    "## find_token that return the list of tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "id": "3c319c76",
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_token(texts):\n",
    "    for text in texts:\n",
    "        text = re.sub(r'\\(', r' ( ', text)\n",
    "        text = re.sub(r'\\)', r' ) ', text)\n",
    "        text = re.sub(r'\\;', r' ;', text)\n",
    "        text = re.sub(r'“', r'\"', text)\n",
    "        text = re.sub(r'”', r'\"', text)\n",
    "        lexems =re.findall(r'\"[.*]?\"|[^\\s]+|[\\S\"]+', text)\n",
    "\n",
    "        qoute_flag=False\n",
    "        x=-1\n",
    "        #print(lexems)\n",
    "        for le in lexems:\n",
    "            if qoute_flag==True:\n",
    "                if le[len(le)-1]==\"\\\"\":\n",
    "                    qoute_flag=False\n",
    "                continue\n",
    "\n",
    "            if le[0] == \"\\\"\" and le[len(le)-1]!=\"\\\"\":\n",
    "                x=text.find(\"\\\"\",x+1)\n",
    "                st = text[x:(text.find(\"\\\"\",x+1))+1]\n",
    "                x=text.find(\"\\\"\",x+1)\n",
    "                if x!=-1:\n",
    "                    if st[len(st)-1]==\"\\\"\":\n",
    "                        qoute_flag=True\n",
    "                        new_token = token(st, Token_type.string)\n",
    "                        Tokens.append(new_token)\n",
    "                        Tokens_comment.append(new_token)\n",
    "                        continue\n",
    "\n",
    "            if (le.lower() in ReservedWords):\n",
    "                new_token = token(le, ReservedWords[le.lower()])\n",
    "                Tokens.append(new_token)\n",
    "                Tokens_comment.append(new_token)\n",
    "\n",
    "            elif (re.match(\";\\w*\", le)):\n",
    "                st=text[text.find(\";\"):]\n",
    "                if(text.endswith('\\n')):\n",
    "                    new_token = token(st[:len(st)-1], Token_type.comment)\n",
    "                    Tokens_comment.append(new_token)\n",
    "                else: \n",
    "                    new_token = token(st, Token_type.comment)\n",
    "                    Tokens_comment.append(new_token)\n",
    "                break\n",
    "            \n",
    "            elif (le in Operators):\n",
    "                new_token = token(le, Operators[le])\n",
    "                Tokens.append(new_token)\n",
    "                Tokens_comment.append(new_token)\n",
    "\n",
    "            elif (re.match(\"^[+|-]?\\d+(\\.[0-9]+)?$\", le)):\n",
    "                new_token = token(le, Token_type.Constant)\n",
    "                Tokens.append(new_token)\n",
    "                Tokens_comment.append(new_token)\n",
    "                \n",
    "            elif (re.match(\"^([a-zA-Z][a-zA-Z0-9]*)$\", le)):\n",
    "                new_token = token(le, Token_type.Identifier)\n",
    "                Tokens.append(new_token)\n",
    "                Tokens_comment.append(new_token)\n",
    "\n",
    "            elif (le[0]==\"\\\"\" and le[len(le)-1]==\"\\\"\"):\n",
    "                new_token = token(le, Token_type.string)\n",
    "                Tokens.append(new_token)\n",
    "                Tokens_comment.append(new_token)\n",
    "\n",
    "            else:\n",
    "                new_token = token(le, Token_type.Error)\n",
    "                Tokens.append(new_token)\n",
    "                Tokens_comment.append(new_token)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "3e65d114",
   "metadata": {},
   "source": [
    "## Check Operators"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "id": "e394bf1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_reserverd_word(j):\n",
    "    if (Tokens[j].token_type == Token_type.when or Tokens[j].token_type == Token_type.read or\n",
    "         Tokens[j].token_type == Token_type.setq or Tokens[j].token_type == Token_type.Print\n",
    "         or Tokens[j].token_type == Token_type.dotimes or Tokens[j].token_type == Token_type.if_statement \n",
    "         or Tokens[j].token_type == Token_type.incf or Tokens[j].token_type == Token_type.decf):\n",
    "        return True\n",
    "    else:\n",
    "        return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "id": "f3a07244",
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_arithmetic_operator(j):\n",
    "    if (Tokens[j].token_type == Token_type.PlusOp or Tokens[j].token_type == Token_type.MinusOp or\n",
    "         Tokens[j].token_type == Token_type.MultiplyOp or Tokens[j].token_type == Token_type.DivideOp or\n",
    "           Tokens[j].token_type == Token_type.mod or Tokens[j].token_type == Token_type.rem):\n",
    "        return True\n",
    "    else:\n",
    "        return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "id": "d1bfc4b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_logical_operator(j):\n",
    "    if (Tokens[j].token_type == Token_type.and_op or Tokens[j].token_type == Token_type.or_op or\n",
    "         Tokens[j].token_type == Token_type.not_op):\n",
    "        return True\n",
    "    else:\n",
    "        return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "id": "bd401e5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_comparison_operator(j):\n",
    "    if (Tokens[j].token_type == Token_type.EqualOp or Tokens[j].token_type == Token_type.LessThanOp or\n",
    "         Tokens[j].token_type == Token_type.GreaterThanOp or Tokens[j].token_type == Token_type.greaterThanOrEqual or\n",
    "           Tokens[j].token_type == Token_type.lessThanOrEqual):\n",
    "        return True\n",
    "    else:\n",
    "        return False"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "00b011f3",
   "metadata": {},
   "source": [
    "## Parser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "id": "36195288",
   "metadata": {},
   "outputs": [],
   "source": [
    "def Match(a,j):\n",
    "    output=dict()\n",
    "    if(j<len(Tokens)):\n",
    "        Temp=Tokens[j].to_dict()\n",
    "        if(Temp['token_type']==a):\n",
    "            j+=1\n",
    "            output[\"node\"]=[Temp['Lex']]\n",
    "            output[\"index\"]=j\n",
    "            return output\n",
    "        else:\n",
    "            output[\"node\"]=[\"error\"]\n",
    "            output[\"index\"]=j+1\n",
    "            errors.append(\"Syntax error : \"+Temp['Lex']+\" Expected dot\")\n",
    "            return output\n",
    "    else:\n",
    "        output[\"node\"]=[\"error\"]\n",
    "        output[\"index\"]=j+1\n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "id": "d3563c52",
   "metadata": {},
   "outputs": [],
   "source": [
    "def list_(j):\n",
    "    children=[]\n",
    "    my_dictio=dict()\n",
    "    if (j < len(Tokens)):\n",
    "            temp=Tokens[j].to_dict()\n",
    "            last_index=j\n",
    "            if (temp[\"token_type\"]==Token_type.comment):\n",
    "                j+=1\n",
    "            if(temp[\"token_type\"]==Token_type.left_brace):\n",
    "                match_list= list(last_index)\n",
    "                children.append(match_list['node'])\n",
    "                match_list_ = list_(match_list['index'])\n",
    "                if match_list_['node'] != None:\n",
    "                    children.append(match_list_['node'])\n",
    "                    last_index=match_list_['index']\n",
    "                else:\n",
    "                    last_index = match_list['index']\n",
    "            else:\n",
    "                Node=Tree(\"List\",children)\n",
    "                my_dictio['node']=None\n",
    "                my_dictio['index']=j \n",
    "                return my_dictio\n",
    "\n",
    "    else:\n",
    "        last_index=j\n",
    "        Node=Tree(\"List_4\",children)\n",
    "        my_dictio['node']=None\n",
    "        my_dictio['index']=last_index \n",
    "        return my_dictio        \n",
    "\n",
    "    Node=Tree(\"List\",children)\n",
    "    my_dictio['node']=Node\n",
    "    my_dictio['index']=last_index \n",
    "    return my_dictio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "id": "10c29ea7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def lists(j):\n",
    "    children=[]\n",
    "    my_dictio=dict()\n",
    "    match_list= list(j)\n",
    "    children.append(match_list['node'])\n",
    "    match_list_ = list_(match_list['index'])\n",
    "    if (match_list_['node'] != None ):\n",
    "        children.append(match_list_['node'])\n",
    "        Node=Tree(\"Lists\",children)\n",
    "        my_dictio['node']=Node\n",
    "        my_dictio['index']=match_list_['index']\n",
    "        return my_dictio\n",
    "    else:   \n",
    "        Node=Tree(\"Lists\",children)\n",
    "        my_dictio['node']=Node\n",
    "        my_dictio['index']=match_list['index']\n",
    "        return my_dictio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "id": "b8b78d5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def atoms_(j):\n",
    "    children=[]\n",
    "    my_dictio=dict()\n",
    "    if (j < len(Tokens)):\n",
    "            temp=Tokens[j].to_dict()\n",
    "            last_index=j\n",
    "            if(temp[\"token_type\"]==Token_type.Constant or temp[\"token_type\"]==Token_type.string):\n",
    "                match_atom= atom(last_index)\n",
    "                children.append(match_atom['node'])\n",
    "                last_index = match_atom['index']\n",
    "                match_atom_ = list_(last_index)\n",
    "                if match_atom_['node'] != None:\n",
    "                    children.append(match_atom_['node'])\n",
    "                    last_index=match_atom_['index']\n",
    "\n",
    "        \n",
    "            else:\n",
    "                Node=Tree(\"Atom_2\",children)\n",
    "                my_dictio['node']=None\n",
    "                my_dictio['index']=last_index \n",
    "                return my_dictio\n",
    "    \n",
    "    else:\n",
    "        last_index=j\n",
    "        Node=Tree(\"Atom_4\",children)\n",
    "        my_dictio['node']=None\n",
    "        my_dictio['index']=last_index \n",
    "        return my_dictio        \n",
    "\n",
    "    Node=Tree(\"Atom\",children)\n",
    "    my_dictio['node']=Node\n",
    "    my_dictio['index']=last_index \n",
    "    return my_dictio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "id": "8cad4b98",
   "metadata": {},
   "outputs": [],
   "source": [
    "def atoms(j):\n",
    "    children=[]\n",
    "    my_dictio=dict()\n",
    "    match_atom = atom(j)\n",
    "    children.append(match_atom['node'])\n",
    "    j = match_atom['index']\n",
    "    match_atoms_ = atoms_(j)\n",
    "    if match_atoms_['node'] != None:\n",
    "        children.append(match_atoms_['node'])\n",
    "        j=match_atoms_['index']\n",
    "\n",
    "\n",
    "    Node=Tree(\"Atoms\",children)\n",
    "    my_dictio['node']=Node\n",
    "    my_dictio['index']=j\n",
    "    return my_dictio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "id": "c5bc4380",
   "metadata": {},
   "outputs": [],
   "source": [
    "def boolean(j):\n",
    "    children=[]\n",
    "    my_dictio=dict()\n",
    "    if(j<len(Tokens)):\n",
    "        temp=Tokens[j].to_dict()\n",
    "        last_index=j\n",
    "        if(temp['token_type']==Token_type.true):\n",
    "            match_true = Match(Token_type.true, j)\n",
    "            children.append(match_true['node'])\n",
    "            last_index= match_true['index']\n",
    "        elif(temp['token_type']==Token_type.false):\n",
    "            match_false =Match(Token_type.false, j)\n",
    "            children.append(match_false['node'])\n",
    "            last_index= match_false['index']\n",
    "\n",
    "        \n",
    "    Node=Tree(\"Boolean\",children)\n",
    "    my_dictio['node']=Node\n",
    "    my_dictio['index']=last_index\n",
    "    return my_dictio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "id": "b61a87a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def Comparison_op(j):\n",
    "    children=[]\n",
    "    my_dictio=dict()\n",
    "    if (Tokens[j].token_type == Token_type.EqualOp):\n",
    "        match_equal=Match(Token_type.EqualOp,j)\n",
    "        children.append(match_equal['node'])\n",
    "    elif (Tokens[j].token_type == Token_type.greaterThanOrEqual):\n",
    "        match_greaterthanorequal=Match(Token_type.greaterThanOrEqual,j)\n",
    "        children.append(match_greaterthanorequal['node'])\n",
    "    elif (Tokens[j].token_type == Token_type.lessThanOrEqual):\n",
    "        match_lessthanorequal=Match(Token_type.lessThanOrEqual,j)\n",
    "        children.append(match_lessthanorequal['node'])\n",
    "    elif (Tokens[j].token_type == Token_type.GreaterThanOp):\n",
    "        match_greaterthan=Match(Token_type.GreaterThanOp,j)\n",
    "        children.append(match_greaterthan['node'])\n",
    "    elif (Tokens[j].token_type == Token_type.LessThanOp):\n",
    "        match_lessthan=Match(Token_type.LessThanOp,j)\n",
    "        children.append(match_lessthan['node'])\n",
    "    \n",
    "    Node=Tree(\"Comparision OP\",children)\n",
    "    my_dictio['node']=Node\n",
    "    my_dictio['index']=j+1\n",
    "    return my_dictio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "id": "b302ee42",
   "metadata": {},
   "outputs": [],
   "source": [
    "def identifier(j): \n",
    "    children=[]\n",
    "    my_dictio=dict()\n",
    "    match_id=Match(Token_type.Identifier,j)\n",
    "    children.append(match_id['node'])\n",
    "    \n",
    "    Node=Tree(\"identifier\",children)\n",
    "    my_dictio['node']=Node\n",
    "    my_dictio['index']=match_id['index']\n",
    "    return my_dictio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "id": "cb1115e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def atom_identifier_(j):   \n",
    "    children=[]\n",
    "    my_dictio=dict()\n",
    "    if (Tokens[j].token_type == Token_type.true or Tokens[j].token_type == Token_type.false\n",
    "         or Tokens[j].token_type == Token_type.Constant or Tokens[j].token_type == Token_type.string):\n",
    "        match_atoms = atoms(j)\n",
    "        if (match_atoms['node'] != None):\n",
    "            children.append(match_atoms['node']) \n",
    "            j = match_atoms['index']\n",
    "        match_atom_id_ = atom_identifier_(j)\n",
    "        if (match_atom_id_['node'] != None):\n",
    "            children.append(match_atom_id_['node'])\n",
    "            j = match_atom_id_['index']\n",
    "    elif(Tokens[j].token_type == Token_type.Identifier):\n",
    "        match_id = identifier(j)\n",
    "        children.append(match_id['node'])\n",
    "        j = match_id['index']\n",
    "        if(Tokens[j].token_type == Token_type.left_brace):\n",
    "            match_list = lists(j)\n",
    "            children.append(match_list['node'])\n",
    "            j = match_list['index']\n",
    "        \n",
    "        match_atom_id_2 = atom_identifier_(j)\n",
    "        if (match_atom_id_2['node'] != None):\n",
    "            children.append(match_atom_id_2['node'])\n",
    "            j = match_atom_id_2['index']\n",
    "    else:\n",
    "        my_dictio['node']=None\n",
    "        my_dictio['index']=j-1\n",
    "        return my_dictio\n",
    "\n",
    "\n",
    "    Node=Tree(\"Atoms_ID\",children)\n",
    "    my_dictio['node']=Node\n",
    "    my_dictio['index']=j\n",
    "    return my_dictio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "id": "f7634d80",
   "metadata": {},
   "outputs": [],
   "source": [
    "def atoms_identifier(j):\n",
    "    children=[]\n",
    "    my_dictio=dict()\n",
    "    if (Tokens[j].token_type == Token_type.true or Tokens[j].token_type == Token_type.false\n",
    "         or Tokens[j].token_type == Token_type.Constant or Tokens[j].token_type == Token_type.string):\n",
    "        match_atoms = atoms(j)\n",
    "        if (match_atoms['node'] != None):\n",
    "            children.append(match_atoms['node']) \n",
    "            j = match_atoms['index']\n",
    "        match_atom_id_ = atom_identifier_(j)\n",
    "        if (match_atom_id_['node'] != None):\n",
    "            children.append(match_atom_id_['node'])\n",
    "            j = match_atom_id_['index']\n",
    "    elif(Tokens[j].token_type == Token_type.Identifier):\n",
    "        match_id = identifier(j)\n",
    "        children.append(match_id['node'])\n",
    "        j = match_id['index']\n",
    "        if(Tokens[j].token_type == Token_type.left_brace):\n",
    "            match_list = lists(j)\n",
    "            children.append(match_list['node'])\n",
    "            j = match_list['index']\n",
    "        match_atom_id_2 = atom_identifier_(j)\n",
    "        if (match_atom_id_2['node'] != None):\n",
    "            children.append(match_atom_id_2['node'])\n",
    "            j = match_atom_id_2['index']\n",
    "    \n",
    "    else:\n",
    "        my_dictio['node']=None\n",
    "        my_dictio['index']=j-1\n",
    "        return my_dictio\n",
    "    Node=Tree(\"Atoms_ID\",children)\n",
    "    my_dictio['node']=Node\n",
    "    my_dictio['index']=j\n",
    "    return my_dictio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "id": "c37da61d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def constant(j): \n",
    "    children=[]\n",
    "    my_dictio=dict()\n",
    "\n",
    "    match_constant=Match(Token_type.Constant,j)\n",
    "    children.append(match_constant['node'])\n",
    "    Node=Tree(\"constant\",children)\n",
    "    my_dictio['node']=Node\n",
    "    my_dictio['index']=match_constant['index']\n",
    "    return my_dictio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "id": "32de8822",
   "metadata": {},
   "outputs": [],
   "source": [
    "def decf(j):\n",
    "    children=[]\n",
    "    my_dictio=dict()\n",
    "    match_id=identifier(j)\n",
    "    children.append(match_id['node'])\n",
    "    if (Tokens[j].token_type == Token_type.Constant):\n",
    "        match_const = constant(match_id['index'])\n",
    "        children.append(match_const['node'])\n",
    "    elif (Tokens[j].token_type == Token_type.Identifier):\n",
    "        match_id2=identifier(match_id['index'])\n",
    "        children.append(match_id2['node'])\n",
    "\n",
    "    Node=Tree(\"Incf Block\",children)\n",
    "    my_dictio['node']=Node\n",
    "    my_dictio['index']=match_id['index'] + 1\n",
    "    return my_dictio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "id": "3ca7d8cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def id_or_constant(j): \n",
    "    children=[]\n",
    "    my_dictio=dict()\n",
    "    if(j<len(Tokens)):\n",
    "        temp=Tokens[j].to_dict()\n",
    "        last_index=j\n",
    "        if(temp['token_type'] == Token_type.Identifier):\n",
    "            match_id = identifier(last_index)\n",
    "            children.append(match_id['node'])\n",
    "            last_index= match_id['index']\n",
    "        elif(temp['token_type']== Token_type.Constant):\n",
    "            match_constant=constant(last_index)\n",
    "            children.append(match_constant['node'])\n",
    "            last_index= match_constant['index']\n",
    "\n",
    "    Node=Tree(\"id or constant\",children)\n",
    "    my_dictio['node']=Node\n",
    "    my_dictio['index']=j+1\n",
    "    return my_dictio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "id": "dc83de8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def dotimes(j):\n",
    "    children=[]\n",
    "    my_dictio=dict()\n",
    "    match_lbrace=Match(Token_type.left_brace,j)\n",
    "    children.append(match_lbrace['node'])\n",
    "    \n",
    "    match_id=identifier(match_lbrace['index'])\n",
    "    children.append(match_id['node'])\n",
    "    j = match_id['index']\n",
    "    if(Tokens[j].token_type == Token_type.left_brace):\n",
    "        match_lists=lists(j)\n",
    "        children.append(match_lists['node'])\n",
    "        j = match_lists['index']\n",
    "    elif(Tokens[j].token_type == Token_type.Identifier or Tokens[j].token_type == Token_type.Constant):\n",
    "        match_id_const=id_or_constant(j)\n",
    "        children.append(match_id_const['node'])\n",
    "        j = match_id_const['index']\n",
    "\n",
    "    match_rbrace=Match(Token_type.right_brace,j)\n",
    "    children.append(match_rbrace['node'])\n",
    "    match_lists = lists(match_rbrace['index'])\n",
    "    children.append(match_lists['node'])\n",
    "\n",
    "    Node=Tree(\"Dotimes Block\",children)\n",
    "    my_dictio['node']=Node\n",
    "    my_dictio['index']=match_lists['index']\n",
    "    return my_dictio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "id": "1ef369fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "def setq(j):\n",
    "    children=[]\n",
    "    my_dictio=dict()\n",
    "    match_id = identifier(j)\n",
    "    children.append(match_id['node'])\n",
    "    j = match_id['index']\n",
    "\n",
    "    if (Tokens[j].token_type == Token_type.left_brace):\n",
    "        match_lists = lists(j)\n",
    "        children.append(match_lists['node'])\n",
    "        j = match_lists['index']\n",
    "\n",
    "    elif(Tokens[j].token_type == Token_type.Identifier or Tokens[j].token_type == Token_type.Constant):\n",
    "        match_id_const= id_or_constant(j)\n",
    "        children.append(match_id_const['node'])\n",
    "        j = match_id_const['index']\n",
    "\n",
    "    \n",
    "    Node=Tree(\"Setq Block\",children)\n",
    "    my_dictio['node']=Node\n",
    "    my_dictio['index']=j\n",
    "    return my_dictio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "id": "31bdcdec",
   "metadata": {},
   "outputs": [],
   "source": [
    "def defconstant(j):\n",
    "    children=[]\n",
    "    my_dictio=dict()\n",
    "    match_id = identifier(j)\n",
    "    children.append(match_id['node'])\n",
    "    j = match_id['index']\n",
    "\n",
    "    if (Tokens[j].token_type == Token_type.left_brace):\n",
    "        match_lists = lists(j)\n",
    "        children.append(match_lists['node'])\n",
    "        j = match_lists['index']\n",
    "\n",
    "    elif(Tokens[j].token_type == Token_type.Identifier or Tokens[j].token_type == Token_type.Constant):\n",
    "        match_id_const= id_or_constant(j)\n",
    "        children.append(match_id_const['node'])\n",
    "        j = match_id_const['index']\n",
    "\n",
    "    \n",
    "    Node=Tree(\"Constant Block\",children)\n",
    "    my_dictio['node']=Node\n",
    "    my_dictio['index']=j\n",
    "    return my_dictio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "id": "43a520b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def read(j):\n",
    "    children=[]\n",
    "    my_dictio=dict()\n",
    "    match_id=identifier(j)\n",
    "    children.append(match_id['node'])\n",
    "\n",
    "    Node=Tree(\"Read Block\",children)\n",
    "    my_dictio['node']=Node\n",
    "    my_dictio['index']=match_id['index']\n",
    "    return my_dictio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "id": "0c8b401f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def incf(j):\n",
    "    children=[]\n",
    "    my_dictio=dict()\n",
    "    match_id=identifier(j)\n",
    "    children.append(match_id['node'])\n",
    "    j = match_id['index']\n",
    "\n",
    "    if(Tokens[j].token_type == Token_type.left_brace):\n",
    "        match_lists = lists(j)\n",
    "        children.append(match_lists['node'])\n",
    "        j = match_lists['index']\n",
    "    elif(Tokens[j].token_type == Token_type.Constant or Tokens[j].token_type == Token_type.Identifier):\n",
    "        match_id_const = id_or_constant(match_id['index'])\n",
    "        children.append(match_id_const['node'])\n",
    "        j = match_id_const['index']\n",
    "    \n",
    "    \n",
    "    Node=Tree(\"Incf Block\",children)\n",
    "    my_dictio['node']=Node\n",
    "    my_dictio['index']=j\n",
    "    return my_dictio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "id": "92a0cd6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def conditional(j):\n",
    "    children=[]\n",
    "    my_dictio=dict()\n",
    "    if(j<len(Tokens)):\n",
    "        temp=Tokens[j].to_dict()\n",
    "        last_index=j\n",
    "        if(temp['token_type'] == Token_type.true or temp['token_type'] == Token_type.false):\n",
    "            match_bool = boolean(last_index)\n",
    "            children.append(match_bool['node'])\n",
    "            last_index = match_bool['index']\n",
    "        elif(temp['token_type'] == Token_type.Identifier or temp['token_type'] == Token_type.Constant):\n",
    "            match_id = id_or_constant(last_index)\n",
    "            children.append(match_id['node'])\n",
    "            last_index = match_id['index']\n",
    "        elif(check_comparison_operator(last_index)):\n",
    "            match_comparison = Comparison_op(last_index)\n",
    "            children.append(match_comparison['node'])\n",
    "            match_id1 = id_or_constant(match_comparison['index'])\n",
    "            children.append(match_id1['node'])\n",
    "            match_id2 = id_or_constant(match_id1['index'])\n",
    "            children.append(match_id2['node'])\n",
    "            last_index= match_id2['index']\n",
    "    \n",
    "    Node=Tree(\"Conditional\",children)\n",
    "    my_dictio['node']=Node\n",
    "    my_dictio['index']=last_index\n",
    "    return my_dictio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "id": "2a4d3c3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def if_statement(j):\n",
    "    children=[]\n",
    "    my_dictio=dict()\n",
    "    match_conditional = conditional(j)\n",
    "    children.append(match_conditional['node'])\n",
    "    match_lists = lists(match_conditional['index'])\n",
    "    children.append(match_lists['node'])\n",
    "\n",
    "    \n",
    "    Node=Tree(\"IF Block\",children)\n",
    "    my_dictio['node']=Node\n",
    "    my_dictio['index']=match_lists['index']\n",
    "    return my_dictio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "id": "bc2a945e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def when(j):\n",
    "    children=[]\n",
    "    my_dictio=dict()\n",
    "    match_lbrace=Match(Token_type.left_brace,j)\n",
    "    children.append(match_lbrace['node'])\n",
    "    match_conditional = conditional(match_lbrace['index'])\n",
    "    children.append(match_conditional['node'])\n",
    "    match_rbrace=Match(Token_type.right_brace,match_conditional['index'])\n",
    "    children.append(match_rbrace['node'])\n",
    "    match_lists = lists(match_rbrace['index'])\n",
    "    children.append(match_lists['node'])\n",
    "\n",
    "    Node=Tree(\"When Block\",children)\n",
    "    my_dictio['node']=Node\n",
    "    my_dictio['index']=match_lists['index']\n",
    "    return my_dictio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "id": "7bc37396",
   "metadata": {},
   "outputs": [],
   "source": [
    "def Arithmeticop(j):\n",
    "    children=[]\n",
    "    my_dictio=dict()\n",
    "    if(Tokens[j].token_type == Token_type.PlusOp):\n",
    "        match_plus=Match(Token_type.PlusOp,j)\n",
    "        children.append(match_plus['node'])\n",
    "    elif(Tokens[j].token_type == Token_type.MinusOp):\n",
    "        match_minus=Match(Token_type.MinusOp,j)\n",
    "        children.append(match_minus['node'])\n",
    "    elif(Tokens[j].token_type == Token_type.MultiplyOp):\n",
    "        match_times=Match(Token_type.MultiplyOp,j)\n",
    "        children.append(match_times['node'])\n",
    "    elif(Tokens[j].token_type == Token_type.DivideOp):\n",
    "        match_divide=Match(Token_type.DivideOp,j)\n",
    "        children.append(match_divide['node'])\n",
    "    elif(Tokens[j].token_type == Token_type.rem):\n",
    "        match_rem=Match(Token_type.rem,j)\n",
    "        children.append(match_rem['node'])\n",
    "    elif(Tokens[j].token_type == Token_type.mod):\n",
    "        match_mod=Match(Token_type.mod,j)\n",
    "        children.append(match_mod['node'])\n",
    "    Node=Tree(\"Arithmetic OP\",children)\n",
    "    my_dictio['node']=Node\n",
    "    my_dictio['index']=j+1\n",
    "    return my_dictio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "id": "35b4c169",
   "metadata": {},
   "outputs": [],
   "source": [
    "def Logicalop(j):\n",
    "    children=[]\n",
    "    my_dictio=dict()\n",
    "    if(Tokens[j].token_type == Token_type.and_op):\n",
    "        match_and=Match(Token_type.and_op,j)\n",
    "        children.append(match_and['node'])\n",
    "    elif(Tokens[j].token_type == Token_type.or_op):\n",
    "        match_or=Match(Token_type.or_op,j)\n",
    "        children.append(match_or['node'])\n",
    "    elif(Tokens[j].token_type == Token_type.not_op):\n",
    "        match_or=Match(Token_type.not_op,j)\n",
    "        children.append(match_or['node'])\n",
    "    Node=Tree(\"Logical OP\",children)\n",
    "    my_dictio['node']=Node\n",
    "    my_dictio['index']=j+1\n",
    "    return my_dictio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "id": "e14804b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def operator(j):\n",
    "    children=[]\n",
    "    my_dictio=dict()\n",
    "    if(check_arithmetic_operator(j)):\n",
    "        match_arithmetic = Arithmeticop(j)\n",
    "        children.append(match_arithmetic['node'])\n",
    "    elif (check_comparison_operator(j)):\n",
    "        match_comparison = Comparison_op(j)\n",
    "        children.append(match_comparison['node'])\n",
    "    elif(check_logical_operator(j)):\n",
    "        match_logical = Logicalop(j)\n",
    "        children.append(match_logical['node'])\n",
    "    Node=Tree(\"Operator\",children)\n",
    "    my_dictio['node']=Node\n",
    "    my_dictio['index']=j+1\n",
    "    return my_dictio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "id": "c70dd529",
   "metadata": {},
   "outputs": [],
   "source": [
    "def string(j):\n",
    "    children=[]\n",
    "    my_dictio=dict()\n",
    "    match_string=Match(Token_type.string,j)\n",
    "    children.append(match_string['node'])\n",
    "\n",
    "    Node=Tree(\"String\",children)\n",
    "    my_dictio['node']=Node\n",
    "    my_dictio['index']=match_string['index']\n",
    "    return my_dictio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "id": "1d7ad17b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def Statement(j):\n",
    "   children=[]\n",
    "   my_dictio=dict()\n",
    "   if(j<len(Tokens)):\n",
    "        temp=Tokens[j].to_dict()\n",
    "        last_index=j\n",
    "\n",
    "        if(temp[\"token_type\"]==Token_type.when):\n",
    "            out=Match(Token_type.when,last_index)\n",
    "            children.append(out['node'])\n",
    "            last_index=out['index']\n",
    "            match_when = when(last_index)\n",
    "            children.append(match_when['node'])\n",
    "            last_index=match_when['index']\n",
    "\n",
    "        elif(temp[\"token_type\"]==Token_type.dotimes):\n",
    "            out=Match(Token_type.dotimes,last_index)\n",
    "            children.append(out['node'])\n",
    "            last_index=out['index']\n",
    "            match_dotimes = dotimes(last_index)\n",
    "            children.append(match_dotimes['node'])\n",
    "            last_index=match_dotimes['index']\n",
    "\n",
    "        elif(temp[\"token_type\"]==Token_type.if_statement):\n",
    "            out=Match(Token_type.if_statement,last_index)\n",
    "            children.append(out['node'])\n",
    "            last_index=out['index']\n",
    "            match_if = if_statement(last_index)\n",
    "            children.append(match_if['node'])\n",
    "            last_index=match_if['index']\n",
    "\n",
    "        elif(temp[\"token_type\"]==Token_type.setq):\n",
    "            out=Match(Token_type.setq,last_index)\n",
    "            children.append(out['node'])\n",
    "            last_index=out['index']\n",
    "            match_setq = setq(last_index)\n",
    "            children.append(match_setq['node'])\n",
    "            last_index=match_setq['index']\n",
    "\n",
    "        elif(temp[\"token_type\"]==Token_type.defconstant):\n",
    "            out=Match(Token_type.defconstant,last_index)\n",
    "            children.append(out['node'])\n",
    "            last_index=out['index']\n",
    "            match_defconst = defconstant(last_index)\n",
    "            children.append(match_defconst['node'])\n",
    "            last_index=match_defconst['index']\n",
    "\n",
    "        elif(temp[\"token_type\"]==Token_type.read):\n",
    "            out=Match(Token_type.read,last_index)\n",
    "            children.append(out['node'])\n",
    "            last_index=out['index']\n",
    "            match_read = read(last_index)\n",
    "            children.append(match_read['node'])\n",
    "            last_index=match_read['index']\n",
    "\n",
    "        elif(temp[\"token_type\"]==Token_type.write):\n",
    "            out=Match(Token_type.write,last_index)\n",
    "            children.append(out['node'])\n",
    "            last_index=out['index']\n",
    "            match_write = write(last_index)\n",
    "            children.append(match_write['node'])\n",
    "            last_index=match_write['index']\n",
    "\n",
    "        elif(temp[\"token_type\"]==Token_type.print):\n",
    "            out=Match(Token_type.print,last_index)\n",
    "            children.append(out['node'])\n",
    "            last_index=out['index']\n",
    "            match_print = Print(last_index)\n",
    "            children.append(match_print['node'])\n",
    "            last_index=match_print['index']\n",
    "\n",
    "        elif(temp[\"token_type\"]==Token_type.incf):\n",
    "            out=Match(Token_type.incf,last_index)\n",
    "            children.append(out['node'])\n",
    "            last_index=out['index']\n",
    "            match_incf = incf(last_index)\n",
    "            children.append(match_incf['node'])\n",
    "            last_index=match_incf['index']\n",
    "\n",
    "        elif(temp[\"token_type\"]==Token_type.decf):\n",
    "            out=Match(Token_type.decf,last_index)\n",
    "            children.append(out['node'])\n",
    "            last_index=out['index']\n",
    "            match_decf = decf(last_index)\n",
    "            children.append(match_decf['node'])\n",
    "            last_index=match_decf['index']\n",
    "\n",
    "        elif(check_arithmetic_operator(last_index) or check_comparison_operator(last_index) or check_logical_operator(last_index)):\n",
    "            out = operator(last_index)\n",
    "            children.append(out['node'])\n",
    "            last_index=out['index']\n",
    "            match_state_ = statement_(last_index)\n",
    "            children.append(match_state_['node'])\n",
    "            last_index=match_state_['index']\n",
    "            if (Tokens[last_index].token_type == Token_type.Constant or Tokens[last_index].token_type == Token_type.Identifier ):\n",
    "                out = id_or_constant(last_index)\n",
    "                children.append(out['node'])\n",
    "                last_index = out['index']\n",
    "            elif(Tokens[last_index].token_type==Token_type.left_brace):\n",
    "                out = lists(last_index)\n",
    "                children.append(out['node'])\n",
    "                last_index = out['index']\n",
    "            \n",
    "       \n",
    "   else:\n",
    "        out =Match(Token_type.Error,j)\n",
    "        children.append(out['node'])\n",
    "        last_index=out['index']\n",
    "\n",
    "\n",
    "   Node=Tree(\"Statement\",children)\n",
    "   my_dictio['node']=Node\n",
    "   my_dictio['index']=last_index\n",
    "   return my_dictio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "id": "9d63aef3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def atom(j):\n",
    "    children=[]\n",
    "    my_dictio=dict()\n",
    "    if(Tokens[j].token_type == Token_type.Constant):\n",
    "        match_constant=constant(j)\n",
    "        children.append(match_constant['node'])\n",
    "    elif (Tokens[j].token_type == Token_type.string):\n",
    "        match_string=string(j)\n",
    "        children.append(match_string['node'])\n",
    "    elif(Tokens[j].token_type == Token_type.true or Tokens[j].token_type == Token_type.false):\n",
    "        mathc_bool=boolean(j)\n",
    "        children.append(mathc_bool['node'])\n",
    "    else:\n",
    "        my_dictio['node']=None\n",
    "        my_dictio['index']=j\n",
    "        return my_dictio\n",
    "    Node=Tree(\"Atom\",children)\n",
    "    my_dictio['node']=Node\n",
    "    my_dictio['index']=j+1\n",
    "    return my_dictio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "id": "e8cb6912",
   "metadata": {},
   "outputs": [],
   "source": [
    "def write(j):\n",
    "    children=[]\n",
    "    my_dictio=dict()\n",
    "    if(j<len(Tokens)):\n",
    "        temp=Tokens[j].to_dict()\n",
    "        last_index=j\n",
    "        if(temp['token_type']==Token_type.Constant or temp['token_type']==Token_type.string):\n",
    "            match_atom = atom(j)\n",
    "            children.append(match_atom['node'])\n",
    "            last_index= match_atom['index']\n",
    "        elif(temp['token_type']==Token_type.Identifier):\n",
    "            match_id=identifier(j)\n",
    "            children.append(match_id['node'])\n",
    "            last_index= match_id['index']\n",
    "        elif(temp['token_type']==Token_type.left_brace):\n",
    "            match_list = lists(j)\n",
    "            children.append(match_list['node'])\n",
    "            last_index= match_list['index']\n",
    "\n",
    "    Node=Tree(\"Write Block\",children)\n",
    "    my_dictio['node']=Node\n",
    "    my_dictio['index']=last_index\n",
    "    return my_dictio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "id": "ba801224",
   "metadata": {},
   "outputs": [],
   "source": [
    "def Print(j):\n",
    "    children=[]\n",
    "    my_dictio=dict()\n",
    "    if(j<len(Tokens)):\n",
    "        temp=Tokens[j].to_dict()\n",
    "        last_index=j\n",
    "        if(temp['token_type']==Token_type.Constant or temp['token_type']==Token_type.string):\n",
    "            match_atom = atom(j)\n",
    "            children.append(match_atom['node'])\n",
    "            last_index= match_atom['index']\n",
    "        elif(temp['token_type']==Token_type.Identifier):\n",
    "            match_id=identifier(j)\n",
    "            children.append(match_id['node'])\n",
    "            last_index= match_id['index']\n",
    "        elif(temp['token_type']==Token_type.left_brace):\n",
    "            match_list = lists(j)\n",
    "            children.append(match_list['node'])\n",
    "            last_index= match_list['index']\n",
    "\n",
    "    Node=Tree(\"Print Block\",children)\n",
    "    my_dictio['node']=Node\n",
    "    my_dictio['index']=last_index\n",
    "    return my_dictio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "id": "8e2d0d08",
   "metadata": {},
   "outputs": [],
   "source": [
    "def statement_(j):\n",
    "    children=[]\n",
    "    my_dictio=dict()\n",
    "    if(j<len(Tokens)):\n",
    "        temp=Tokens[j].to_dict()\n",
    "        last_index=j\n",
    "        if(temp[\"token_type\"]==Token_type.left_brace):\n",
    "            match_lsit = lists(j)\n",
    "            children.append(match_lsit['node'])\n",
    "            last_index=match_lsit['index']\n",
    "        elif(Tokens[j].token_type == Token_type.true or Tokens[j].token_type == Token_type.false\n",
    "         or Tokens[j].token_type == Token_type.Constant or Tokens[j].token_type == Token_type.string\n",
    "           or Tokens[j].token_type == Token_type.Identifier):\n",
    "            match_atom = atoms_identifier(last_index)\n",
    "            children.append(match_atom['node'])\n",
    "            last_index=match_atom['index']\n",
    "\n",
    "    Node=Tree(\"Statement'\",children)\n",
    "    my_dictio['node']=Node\n",
    "    my_dictio['index']=last_index\n",
    "    return my_dictio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "id": "b1813c7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def list(j):\n",
    "   children=[]\n",
    "   my_dictio=dict()\n",
    "   match_lbrace=Match(Token_type.left_brace,j)\n",
    "   children.append(match_lbrace['node'])\n",
    "   match_statment = Statement(match_lbrace['index'])\n",
    "   children.append(match_statment['node'])\n",
    "   match_rbrace=Match(Token_type.right_brace,match_statment['index'])\n",
    "   children.append(match_rbrace['node'])\n",
    "\n",
    "   Node=Tree(\"List\",children)\n",
    "   my_dictio['node']=Node\n",
    "   my_dictio['index']=match_rbrace['index']\n",
    "   return my_dictio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "id": "a6a02460",
   "metadata": {},
   "outputs": [],
   "source": [
    "def Program():\n",
    "    j=0\n",
    "    Children=[]\n",
    "\n",
    "    if(Tokens[j].token_type == Token_type.left_brace):\n",
    "        list_dict = lists(j)\n",
    "        Children.append(list_dict[\"node\"])\n",
    "    elif(Tokens[j].token_type != Token_type.left_brace):\n",
    "        atoms_dict = atoms(j)\n",
    "        Children.append(atoms_dict[\"node\"])\n",
    "\n",
    "    \n",
    "    Node=Tree('Program',Children)\n",
    "    \n",
    "    return Node"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "id": "7954bd92",
   "metadata": {},
   "outputs": [],
   "source": [
    "#GUI\n",
    "root= tk.Tk()\n",
    "\n",
    "canvas1 = tk.Canvas(root, width=400, height=300, relief='raised')\n",
    "canvas1.pack()\n",
    "\n",
    "label1 = tk.Label(root, text='Scanner Phase')\n",
    "label1.config(font=('helvetica', 14))\n",
    "canvas1.create_window(200, 25, window=label1)\n",
    "\n",
    "label2 = tk.Label(root, text='FIle Path:')\n",
    "label2.config(font=('helvetica', 10))\n",
    "canvas1.create_window(200, 100, window=label2)\n",
    "\n",
    "entry1 = tk.Entry(root) \n",
    "canvas1.create_window(200, 140, window=entry1)\n",
    "\n",
    "def Scan():\n",
    "    x1 = entry1.get()\n",
    "    \n",
    "    file = open(x1, 'r')\n",
    "    l = file.readlines()\n",
    "    find_token(l)\n",
    "    df=pandas.DataFrame.from_records([t.to_dict() for t in Tokens_comment])\n",
    "    # print(df)\n",
    "      \n",
    "    \n",
    "    \n",
    "    #to display token stream as table\n",
    "    dTDa1 = tk.Toplevel()\n",
    "    dTDa1.title('Token Stream')\n",
    "    dTDaPT = pt.Table(dTDa1, dataframe=df, showtoolbar=True, showstatusbar=True)\n",
    "    dTDaPT.show()\n",
    "\n",
    "    \n",
    "     \n",
    "    # start Parsing\n",
    "    Node=Program()\n",
    "     \n",
    "    \n",
    "    # to display errorlist\n",
    "    df1=pandas.DataFrame(errors)\n",
    "    dTDa2 = tk.Toplevel()\n",
    "    dTDa2.title('Error List')\n",
    "    dTDaPT2 = pt.Table(dTDa2, dataframe=df1, showtoolbar=True, showstatusbar=True)\n",
    "    dTDaPT2.show()\n",
    "    Node.draw()\n",
    "    \n",
    "    \n",
    "button1 = tk.Button(text='Scan', command=Scan, bg='brown', fg='white', font=('helvetica', 9, 'bold'))\n",
    "canvas1.create_window(200, 180, window=button1)\n",
    "root.mainloop()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
